# System Design â€” Study Notes (v2 â€” deep edition)

> **Updated:** 25/fev/2026
> Ler todo dia. Foco em COMO funciona mecanicamente, nÃ£o sÃ³ O QUE Ã©.

---

## Ãndice

### 1. Ferramentas (Tools)
- [Kafka â€” Distributed Commit Log](#kafka--distributed-commit-log)
- [Redis â€” In-Memory Data Store](#redis--in-memory-data-store)
- [PostgreSQL](#postgresql)

### 2. PadrÃµes de Design (Patterns)
- [Scaling Reads](#scaling-reads--novo)
- [Scaling Writes](#scaling-writes--novo)
- [Real-Time Updates](#real-time-updates--novo)
- [Multi-Step Process](#multi-step-process)
- [Contention](#contention) (Pessimistic Lock, OCC, Saga, 2PC)
  - [Saga Pattern + Pagamentos](#1-saga-pattern--muito-importante-para-sistemas-de-pagamento)
  - [ReconciliaÃ§Ã£o](#reconciliaÃ§Ã£o--a-rede-de-seguranÃ§a-final)
- [Outbox Pattern](#outbox-pattern--aprendi-no-mock--fixando)
- [Async After 200](#async-after-200--aprendi-no-mock--fixando)
- [Token Bucket](#token-bucket--rate-limiting-algorithm)
- [CAP Theorem](#cap-theorem)

### 3. Problemas Praticados
- [Rate Limiter](#rate-limiter)
- [Uber / Ride Matching](#uber--ride-matching)
- [Food Reviews + Payouts](#food-reviews--payouts-mock-24fev--borderline-hire)
- [Job Scheduler](#job-scheduler)

### 4. ReferÃªncia RÃ¡pida
- [Napkin Math](#4-napkin-math--referÃªncia-rÃ¡pida)
- [Framework SD (7 passos)](#5-framework-sd-usar-em-toda-entrevista)
- [Decision Cards](#6-decision-cards)

---

# 1. Ferramentas (Tools)

## Kafka â€” Distributed Commit Log

**O que Ã©:** plataforma de streaming de eventos. Diferente de uma fila tradicional (RabbitMQ/SQS), Kafka Ã© um **LOG APPEND-ONLY** â€” mensagens nÃ£o sÃ£o deletadas apÃ³s consumo. Isso permite replay, mÃºltiplos consumers, e audit trail.

### Como funciona mecanicamente

**Producer publica mensagem:**
1. Producer envia `(key, value, timestamp, headers)` para um topic
2. Se key Ã© null â†’ round-robin entre partitions
   Se key existe â†’ `hash(key) % num_partitions` â†’ sempre mesma partition
3. Mensagem Ã© APPEND ao final do log da partition (nunca modifica dados anteriores)
4. Broker retorna offset (posiÃ§Ã£o no log) como confirmaÃ§Ã£o

**Consumer lÃª mensagem:**
1. Consumer faz `poll()` pedindo mensagens a partir do seu Ãºltimo offset
2. Broker retorna batch de mensagens
3. Consumer processa e faz commit do offset (marca "li atÃ© aqui")
4. Se consumer cair e reiniciar, continua do Ãºltimo offset commitado

### Componentes
- **Brokers:** nÃ³s do cluster. Cada broker armazena partitions.
- **Topics:** agrupamento lÃ³gico (ex: "payments", "votes")
- **Partitions:** unidade de paralelismo. Cada partition = 1 log ordenado.
  > âš ï¸ **IMPORTANTE:** ordering sÃ³ Ã© garantido DENTRO de uma partition, nÃ£o entre partitions.
- **Consumer Groups:** grupo de consumers que dividem partitions entre si.
  - Regra: cada partition â†’ exatamente 1 consumer do grupo.
  - Se 6 partitions e 3 consumers â†’ cada consumer lÃª 2 partitions.
  - Se 6 partitions e 8 consumers â†’ 2 consumers ficam idle (desperdÃ­cio).

### Replication (eu esqueci isso)
- Cada partition tem N cÃ³pias (replication factor, ex: RF=3)
- 1 cÃ³pia Ã© **LEADER** (recebe writes), outras sÃ£o **FOLLOWERS** (replicam)
- Se leader cai, um follower Ã© eleito novo leader (automÃ¡tico via ZooKeeper/KRaft)
- **ISR** (In-Sync Replicas): followers que estÃ£o up-to-date com o leader
- `acks=all`: producer espera todos ISR confirmarem â†’ mais seguro, mais lento
- `acks=1`: producer espera sÃ³ o leader â†’ mais rÃ¡pido, pode perder dados

### Delivery Semantics
| Modo | Como funciona | Risco |
|------|---------------|-------|
| at-most-once | Consumer commita offset ANTES de processar | Pode perder msg |
| **at-least-once (DEFAULT)** | Consumer commita DEPOIS de processar | Pode duplicar â€” precisa idempotÃªncia! |
| exactly-once | Transactional producers + idempotent consumers | Mais caro |

### Kafka como Fila vs Stream
- **Fila (queue):** 1 consumer group, cada msg processada por 1 consumer. Similar a SQS.
- **Stream:** mÃºltiplos consumer groups, cada um lÃª todas as msgs independentemente.
  Ex: mesmo tÃ³pico "orders" Ã© lido pelo PaymentService E pelo NotificationService.

### NÃºmeros
| MÃ©trica | Valor |
|---------|-------|
| Throughput | 1M+ msgs/sec (cluster) |
| LatÃªncia | 2-10ms (publicaÃ§Ã£o), depende do acks |
| RetenÃ§Ã£o | ConfigurÃ¡vel (7 dias default, pode ser infinito) |

**Quando usar:** desacoplamento, event-driven, high throughput, precisa de replay/audit
**Quando NÃƒO usar:** request-response, <100 msgs/sec (overkill), precisa ordering global
**Pitch:** *"I'd use Kafka to decouple services with durable, ordered event delivery and the ability to replay events for recovery"*

---

## Redis â€” In-Memory Data Store

**O que Ã©:** banco in-memory key-value com estruturas de dados ricas.
Single-threaded para commands â†’ **TODA operaÃ§Ã£o Ã© atÃ´mica** por natureza.

### Como funciona mecanicamente

**Write (SET/INCR):**
1. Client envia comando (ex: `INCR review:123:votes`)
2. Redis processa em single thread (nenhum outro comando executa ao mesmo tempo)
3. Modifica o valor na memÃ³ria RAM
4. Retorna resultado ao client
5. Se AOF habilitado, appenda o comando no arquivo de log em disco (async)

**Read (GET):**
1. Client envia comando (ex: `GET user:session:456`)
2. Redis busca na hash table interna â€” **O(1)**
3. Retorna valor â€” latÃªncia: **~microsegundos (sub-millisecond)**

### Estruturas de dados e quando usar cada uma

| Estrutura | O que Ã© | Quando usar | Exemplo |
|-----------|---------|-------------|---------|
| **String** | Valor simples. INCR/DECR atÃ´mico | Counters, cache simples, rate limiting | `INCR review:123:votes` â†’ retorna 457 |
| **Hash** | Objeto com campos | User profile, session data | `HSET user:123 name "JoÃ£o" age 30` |
| **List** | Lista ordenada. LPUSH/RPOP = FIFO | Filas simples, Ãºltimas atividades | `LPUSH notifications:user:123 "new_vote"` |
| **Set** | Conjunto de valores Ãºnicos | Tags, deduplicaÃ§Ã£o | `SADD online_users "user:123"` |
| **Sorted Set (ZSet)** â­ | Set ordenado por SCORE | Leaderboards, top-N, rankings | `ZADD product:42:reviews 457 "review:123"` |
| **HyperLogLog** | Estimativa de contagem Ãºnica (~12KB) | Unique visitors (~99% precisÃ£o) | `PFADD page_views:homepage "user:123"` |
| **Streams** | Log append-only (mini-Kafka) | Event sourcing simples | â€” |

> â­ **Sorted Set Ã© o MAIS IMPORTANTE para entrevistas:**
> - `ZADD product:42:reviews 457 "review:123"` (score = 457 upvotes)
> - `ZREVRANGE product:42:reviews 0 9` (top 10 reviews)
> - Complexidade: O(log N) insert, O(log N + M) range query

### TTL e Eviction (EU ERREI ISSO â€” agora fixado)
- TTL **NÃƒO Ã© automÃ¡tico**. VocÃª seta: `EXPIRE key 3600` (1 hora)
- Sem EXPIRE, dado fica na memÃ³ria **PARA SEMPRE**
- Quando memÃ³ria enche, Redis aplica **EVICTION POLICY:**

| Policy | Comportamento |
|--------|---------------|
| noeviction | Retorna erro (default) |
| allkeys-lru | Remove keys menos recentemente usadas |
| volatile-lru | Remove keys COM TTL menos recentemente usadas |
| allkeys-random | Remove keys aleatÃ³rias |

> ğŸ’¡ *"I'd set TTL on cache entries and use LRU eviction as a safety net when memory pressure increases"*

### PersistÃªncia (se Redis cair, como recuperar?)
| Modo | Como funciona | Trade-off |
|------|---------------|-----------|
| **RDB** (snapshot) | Foto da memÃ³ria a cada X min | RÃ¡pido recovery, perde dados entre snapshots |
| **AOF** (append-only file) | Loga cada write em disco | Seguro (~1 sec perda max), recovery mais lento |
| **HÃ­brido** (RDB + AOF) | Melhor dos dois mundos | Recomendado para produÃ§Ã£o |

### Distributed Lock (como funciona mecanicamente)
```
1. Client A: SET lock:resource:123 "clientA" NX EX 30
   NX = sÃ³ seta se key NÃƒO existe. EX 30 = expira em 30s.
2. Retornou OK â†’ lock adquirido. Client A processa.
3. Retornou nil â†’ outro client tem o lock. Espera ou retry.
4. Client A termina â†’ DEL lock:resource:123 (libera o lock)
5. Se Client A crashar â†’ lock expira em 30s automaticamente (TTL salva)
```
> âš ï¸ **PROBLEMA:** em Redis Cluster, lock pode ser perdido durante failover.
> SoluÃ§Ã£o: **Redlock** (lock em N/2+1 nodes), mas adiciona complexidade.

### Redis Cluster (como distribui dados)
- **16384 hash slots** divididos entre nodes
- Cada key: `CRC16(key) % 16384` â†’ slot â†’ node
- Client sabe qual node tem qual range de slots (gossip protocol)
- Se client manda request pro node errado, recebe **MOVED redirect**
- **Hot keys:** uma key muito acessada sobrecarrega 1 node
  - SoluÃ§Ãµes: (1) read replicas, (2) key splitting, (3) local in-memory cache

### NÃºmeros
| MÃ©trica | Valor |
|---------|-------|
| Throughput | ~100K-300K ops/sec (single node) |
| LatÃªncia | <1ms, tipicamente ~100-200 Î¼s |
| MemÃ³ria | Datasets devem caber na RAM. 1M keys Ã— 1KB = ~1GB |

**Quando usar:** cache, counters, rate limits, sessÃµes, leaderboards, distributed locks
**Quando NÃƒO usar:** durabilidade garantida, joins, datasets > RAM, analytics
**Pitch:** *"I'd use Redis as a caching layer for sub-ms reads, with TTL and LRU eviction"*

---

## PostgreSQL

**O que Ã©:** banco de dados relacional, ACID, open-source. **Source of truth.**

**Quando usar em entrevista:**
- Dados estruturados com relacionamentos e constraints
- Precisa de UNIQUE, FK, CHECK constraints
- Transactions ACID

### Escalabilidade
| NÃ­vel | TÃ©cnica | Detalhe |
|-------|---------|---------|
| 1 | Vertical | Mais CPU/RAM |
| 2 | **Read replicas** | ReplicaÃ§Ã£o assÃ­ncrona. Delay ~ms. Trade-off: eventual consistency |
| 3 | Connection pooling | PgBouncer. Evita exaurir conexÃµes |
| 4 | Partitioning | Dividir tabela por range (date) ou hash (user_id) |
| 5 | **Sharding** | Ãšltimo recurso. SÃ“ quando single primary nÃ£o aguenta (>10K writes/sec) |

### Ãndices
| Tipo | Uso |
|------|-----|
| B-tree (default) | Range queries, equality. O(log N) |
| GIN | Full-text search, JSONB |
| GiST | Geospatial (PostGIS) |

### NÃºmeros
| MÃ©trica | Valor |
|---------|-------|
| Simple inserts | 5,000-10,000/sec (single primary) |
| Indexed reads | 10,000-50,000/sec |
| Complex joins | 100-1,000/sec |

> ğŸ’¡ *"Postgres handles 5-10K inserts/sec easily on single primary. Sharding would be premature at this scale."* â†’ mostra maturidade

---

# 2. PadrÃµes de Design (Patterns)

## Scaling Reads â­ (novo)

**Problema:** sistema tem muitas leituras e o banco principal nÃ£o aguenta.

### ProgressÃ£o de soluÃ§Ãµes (do mais simples ao mais complexo)

**NÃVEL 1 â€” Otimizar dentro do DB**
- Adicionar Ã­ndices (B-tree para queries frequentes)
- Denormalizar dados (evitar joins caros â€” copiar dados redundantes)
- Materializar views para queries complexas recorrentes
- Otimizar queries (`EXPLAIN ANALYZE` para encontrar bottlenecks)

**NÃVEL 2 â€” Escalar horizontalmente o DB**
- **Read replicas:** replicaÃ§Ã£o assÃ­ncrona do primary. App lÃª das replicas.
  - Mecanicamente: primary escreve WAL (Write-Ahead Log) â†’ replica aplica WAL.
  - Trade-off: replica delay (ms-sec). Leitura pode retornar dado stale.
  - Quando ok: feeds, reviews, perfis. Quando NÃƒO ok: saldo bancÃ¡rio.
- Sharding por read pattern: dividir dados por tenant/regiÃ£o se queries sÃ£o isoladas

**NÃVEL 3 â€” Cache externo**
- Redis/Memcached entre app e DB:
  `App â†’ Redis (hit?) â†’ se sim, retorna. Se nÃ£o â†’ Postgres â†’ salva no Redis â†’ retorna`

| Strategy | Como funciona | Trade-off |
|----------|---------------|-----------|
| **Cache-Aside (Lazy)** | App controla. Se miss, lÃª DB e popula cache | Simples, mas cold start lento |
| **Write-Through** | Toda write vai pro cache E pro DB | Cache sempre fresh, mas write mais lento |
| **Write-Behind** | Write vai pro cache, cache escreve no DB async | RÃ¡pido, mas pode perder dados |

- **CDN** para conteÃºdo estÃ¡tico (imagens, CSS, JS)
- **Cache stampede:** quando TTL expira e TODAS requests batem no DB
  - SoluÃ§Ãµes: (1) distributed lock, (2) probabilistic early expiration, (3) stale-while-revalidate

> ğŸ’¡ *"Before adding infrastructure complexity, I'd first optimize the query and add proper indexes. If that's not enough for our QPS, I'd add read replicas."*

---

## Scaling Writes â­ (novo)

**Problema:** muitas escritas e o banco primary nÃ£o aguenta.

**NÃVEL 1 â€” Otimizar o DB**
- Escolher o DB certo (SQL vs NoSQL). DynamoDB/Cassandra escalam writes melhor.
- Batch writes (1000 rows de uma vez vs 1000 inserts individuais)
- Desabilitar indexes desnecessÃ¡rios (cada index = overhead no write)

**NÃVEL 2 â€” Sharding/Partitioning**
- Dividir dados entre mÃºltiplos DB nodes por partition key
- Partition key ideal: distribuiÃ§Ã£o uniforme, queries nÃ£o precisam cross-shard
- Ex: shard by user_id (bom), shard by country (ruim se 1 paÃ­s tem 80% dos dados)
- **Hot key problem:** mesmo com sharding, 1 key recebe todas as writes
  - SoluÃ§Ã£o: **key splitting** (`counter:123` â†’ `counter:123:shard1..shardN`, soma ao ler)

**NÃVEL 3 â€” Write queue/buffer**
- Fila (Kafka/SQS) na frente do DB
- App escreve na fila (rÃ¡pido) â†’ worker consome e escreve no DB (throttled)
- Absorve picos. Trade-off: latÃªncia extra, eventual consistency.

**NÃVEL 4 â€” Hierarchical aggregation**
- Para contadores de alta escala: agregar em camadas
- Ex: 1000 servers contam localmente â†’ a cada 1 sec enviam subtotais â†’ aggregator soma
- Usado pelo YouTube para view counts

**RESHARDING** (pergunta clÃ¡ssica):
- **Consistent hashing:** minimiza redistribuiÃ§Ã£o ao adicionar nodes
- Precisa de migration strategy (dual-write â†’ switch â†’ cleanup)

---

## Real-Time Updates â­ (novo)

**Problema:** como o servidor envia dados para o client em tempo real?

### Arquitetura "Two-Hop"
- **Hop 1:** Source â†’ Server (como o server fica sabendo que algo mudou?)
- **Hop 2:** Server â†’ Client (como o client recebe a atualizaÃ§Ã£o?)

### Hop 2 â€” Server â†’ Client (5 opÃ§Ãµes)

| Protocolo | Como funciona | Pros | Contras | Usar para |
|-----------|---------------|------|---------|-----------|
| **Simple Polling** | Client faz GET a cada X sec | Simples, stateless | DesperdiÃ§a requests, alta latÃªncia | Dashboards, job status |
| **Long Polling** | Server segura conexÃ£o atÃ© ter dados | Menor latÃªncia | ConexÃµes abertas, reconnect apÃ³s cada resposta | Chat bÃ¡sico, notificaÃ§Ãµes |
| **SSE** | ConexÃ£o HTTP unidirecional (serverâ†’client) | Simples, reconexÃ£o auto | Unidirecional, ~6 conexÃµes/domÃ­nio | Feeds real-time, stock prices |
| **WebSocket** â­ | ConexÃ£o bidirecional persistente | Full-duplex, baixa latÃªncia | Stateful, sticky sessions | Chat, location, collaborative editing |
| **WebRTC** | Peer-to-peer direto | Menor latÃªncia possÃ­vel | Complexo, NAT traversal | Video calls, screen sharing |

### WebSocket â€” como funciona mecanicamente
```
1. Client faz HTTP request com header "Upgrade: websocket"
2. Server aceita â†’ conexÃ£o "upgrada" para WebSocket
3. Agora ambos podem enviar dados a qualquer momento (full-duplex)
4. ConexÃ£o fica aberta atÃ© client ou server fechar
```
> âš ï¸ Scaling WebSocket: precisa de sticky sessions ou connection registry. Load balancer precisa suportar WS (ALB sim, CLB nÃ£o).

### Hop 1 â€” Source â†’ Server
1. **Polling do DB:** server faz query a cada X sec. Simples mas desperdiÃ§a resources.
2. **CDC (Change Data Capture):** DB envia stream de mudanÃ§as. Ex: Postgres WAL â†’ Debezium â†’ Kafka
3. **Pub/Sub:** Redis Pub/Sub ou Kafka. ServiÃ§o publica, server subscrito recebe.
4. **Consistent Hashing:** rotear updates para o server que mantÃ©m a conexÃ£o WS do client.

### Fan-Out Problem (muito importante para entrevistas)

Quando 1 evento precisa ser enviado para MUITOS clients/users.
Ex: celebridade posta foto â†’ 10M followers precisam ver no feed.
Ex DoorDash: review popular recebe 10K upvotes â†’ precisa atualizar ranking.

#### Fan-out on WRITE (push model)

**Como funciona mecanicamente:**
```
User A posta review â†’ sistema escreve na "inbox" de CADA follower

1. User A publica review
2. Sistema busca todos os followers de User A: [User B, User C, ..., User Z]
3. Para CADA follower:
   INSERT INTO feed (user_id, review_id, created_at) VALUES (B, 123, now());
   INSERT INTO feed (user_id, review_id, created_at) VALUES (C, 123, now());
   ... (repete para cada follower)
4. Quando User B abre o feed: SELECT * FROM feed WHERE user_id = B ORDER BY created_at
   â†’ RÃ¡pido! JÃ¡ estÃ¡ tudo prÃ©-computado.
```

**NÃºmeros:**
- User com 500 followers â†’ 1 post = 500 writes. Ok.
- Celebridade com 10M followers â†’ 1 post = **10M writes**. Demora minutos!

| Pros | Contras |
|------|---------|
| Leitura muito rÃ¡pida (O(1) por user) | Write amplification massiva |
| Feed sempre pronto quando user abre | Celebridades = bottleneck |
| Simples de implementar a leitura | Storage alto (N cÃ³pias do mesmo dado) |

**Quando usar:** users com poucos followers (<10K), sistemas onde leitura rÃ¡pida Ã© crÃ­tica

#### Fan-out on READ (pull model)

**Como funciona mecanicamente:**
```
User A posta review â†’ sistema escreve APENAS no perfil de User A

1. User A publica review
2. INSERT INTO reviews (user_id, content) VALUES (A, '...');
   â†’ 1 write apenas. RÃ¡pido.
3. Quando User B abre o feed:
   a. Buscar quem User B segue: SELECT following FROM follows WHERE user_id = B
      â†’ Retorna [User A, User C, User D, ...]
   b. Para CADA seguido, buscar posts recentes:
      SELECT * FROM reviews WHERE user_id IN (A, C, D, ...) ORDER BY created_at LIMIT 50
   c. Mergear e ordenar todos os resultados
   d. Retornar para User B
```

**NÃºmeros:**
- User segue 200 pessoas â†’ abrir feed = 200 queries (ou 1 query com IN clause grande)
- Se cada query demora 5ms â†’ 200 Ã— 5ms = **1 segundo** para carregar feed. Lento!

| Pros | Contras |
|------|---------|
| Write rÃ¡pido (1 write apenas) | Leitura lenta (merge de N fontes) |
| Sem write amplification | LatÃªncia alta ao abrir feed |
| Storage eficiente | Mais complexo no read path |

**Quando usar:** celebridades, users com muitos followers, sistemas write-heavy

#### HYBRID (o que Twitter/Instagram/DoorDash fazem) â­

**Como funciona mecanicamente:**
```
Classificar users em 2 categorias:
- Users normais (< 10K followers) â†’ fan-out on WRITE
- Celebridades (> 10K followers) â†’ fan-out on READ

Quando User B abre o feed:
1. Ler inbox prÃ©-computada (posts de users normais que B segue)
   â†’ RÃ¡pido, jÃ¡ estava pronto
2. Buscar posts recentes das celebridades que B segue
   â†’ Poucos (B segue talvez 5-10 celebridades)
3. Mergear os dois resultados e ordenar por timestamp
4. Retornar feed completo
```

**Por que funciona:**
- 99% dos users sÃ£o normais â†’ fan-out on write funciona bem
- 1% sÃ£o celebridades â†’ fan-out on read para poucos users Ã© rÃ¡pido
- O merge final Ã© barato (inbox + poucos pulls)

| Pros | Contras |
|------|---------|
| Balanceia write e read | Mais complexo de implementar |
| Resolve o problema da celebridade | Precisa classificar users (threshold) |
| EscalÃ¡vel para bilhÃµes de users | Duas code paths diferentes |

#### Exemplo aplicado: DoorDash Food Reviews

No Food Reviews, o fan-out aparece quando:
- Um review popular precisa aparecer no **top reviews** de um produto
- Muitos users abrem a mesma pÃ¡gina de produto ao mesmo tempo

**SoluÃ§Ã£o no nosso design:**
- NÃ£o Ã© fan-out clÃ¡ssico (nÃ£o temos followers), mas o princÃ­pio Ã© similar
- **Redis Sorted Set** funciona como fan-out on write para o ranking:
  ```
  Cada upvote â†’ ZADD product:42:reviews {new_score} "review:123"
  Quando user abre produto â†’ ZREVRANGE product:42:reviews 0 9 (top 10)
  ```
- O ranking estÃ¡ **sempre prÃ©-computado** no Redis (push model)
- A leitura Ã© O(log N) â€” sub-millisecond
- Isso Ã© efetivamente **fan-out on write** para o ranking

---

## Multi-Step Process

**O que Ã©:** processos com mÃºltiplas etapas que nÃ£o podem falhar no meio.
**Exemplo:** `order created â†’ payment â†’ picking â†’ confirmation â†’ delivery`

### 3 abordagens
1. **Servidor Ãºnico:** chamadas encadeadas em memÃ³ria. Simples, mas se cair perde estado.
2. **Event Sourcing:** cada serviÃ§o publica e consome eventos com contratos versionados.
3. **Durable Workflows (Temporal/Cadence):** funÃ§Ãµes determinÃ­sticas com estado em banco temporal. Se cair, reinicia de onde parou.

> âš ï¸ **COMPENSATING TRANSACTIONS** â€” quando um step falha, os steps anteriores precisam de rollback (ex: estornar pagamento se picking falhou)

**Bom para:** sistemas financeiros, processos com etapas manuais
**NÃ£o Ã© bom para:** processamento async simples, alta carga de leitura

---

## Contention

**O que Ã©:** mÃºltiplos processos competindo pelo mesmo recurso.
**Exemplos:** tickets de show, transferÃªncias bancÃ¡rias, leilÃµes.

**Pergunta-chave: o dado cabe em um Ãºnico banco de dados?**

### SE SIM (single database)

#### 1. Pessimistic Locking (SELECT FOR UPDATE)

**Como funciona mecanicamente:**
```sql
BEGIN;
SELECT * FROM tickets WHERE id = 1 FOR UPDATE;
-- Neste momento, a linha id=1 estÃ¡ LOCKADA.
-- Nenhuma outra transaÃ§Ã£o consegue ler com FOR UPDATE ou modificar esta linha.
UPDATE tickets SET status = 'sold', buyer_id = 123 WHERE id = 1;
COMMIT;  -- Lock Ã© liberado
```
Se outra transaÃ§Ã£o tentar `SELECT FOR UPDATE` na mesma linha, ela **ESPERA** (bloqueada) atÃ© o COMMIT da primeira.

**Trade-off:** seguro, mas pode causar deadlocks e reduz throughput.
**Usar quando:** conflitos sÃ£o FREQUENTES, dados sÃ£o CRÃTICOS (dinheiro, tickets)

#### 2. Optimistic Concurrency Control (OCC)

**Como funciona mecanicamente:**
```sql
-- LÃª o dado com a versÃ£o atual
SELECT *, version FROM tickets WHERE id = 1;  -- version = 5
-- Processa no application level
-- Tenta atualizar, mas SÃ“ SE a versÃ£o nÃ£o mudou
UPDATE tickets SET status='sold', buyer_id=123, version=6
  WHERE id=1 AND version=5;
-- Se 0 rows affected â†’ alguÃ©m mudou antes. Retry!
-- Se 1 row affected â†’ sucesso.
```

**Trade-off:** melhor throughput, mas retries frequentes se alta contenÃ§Ã£o.
**Usar quando:** conflitos sÃ£o RAROS (editar perfil, atualizar preferÃªncias)

### SE NÃƒO (distributed/multi-database)

#### 1. Saga Pattern â­ (MUITO IMPORTANTE para sistemas de pagamento)

**O que Ã©:** sequÃªncia de transaÃ§Ãµes locais independentes. Cada step Ã© um COMMIT completo no seu prÃ³prio banco. Se um step falha, executa **COMPENSATING TRANSACTIONS** nos steps anteriores (rollback lÃ³gico).

**DiferenÃ§a chave vs transaÃ§Ã£o normal:**
```
TransaÃ§Ã£o ACID: BEGIN â†’ op1 â†’ op2 â†’ op3 â†’ COMMIT (tudo ou nada, 1 banco)
Saga:           op1 COMMIT â†’ op2 COMMIT â†’ op3 COMMIT (cada um independente, N bancos)
                Se op3 falha: compensate op2 â†’ compensate op1
```

##### Exemplo mecÃ¢nico â€” Sistema de Pagamento (DoorDash payout)

**Contexto:** reviewer atingiu threshold de upvotes, precisa receber pagamento.
**ServiÃ§os:** EarningsService (DB1), WalletService (DB2), PaymentGateway (externo)

**FLUXO FELIZ (tudo dÃ¡ certo):**

**Step 1: EarningsService**
```sql
INSERT INTO payouts (review_id, user_id, amount, status)
  VALUES (123, 456, 50.00, 'pending');
COMMIT;  -- transaÃ§Ã£o local completa
-- â†’ Publica evento: "payout_initiated"
```

**Step 2: WalletService** (ouve "payout_initiated")
```sql
UPDATE wallets SET balance = balance + 50.00 WHERE user_id = 456;
INSERT INTO wallet_transactions (user_id, amount, type, payout_id)
  VALUES (456, 50.00, 'credit', 123);
COMMIT;  -- transaÃ§Ã£o local completa
-- â†’ Publica evento: "wallet_credited"
```

**Step 3: PaymentGateway** (ouve "wallet_credited")
```
POST /transfers { amount: 5000, destination: user_stripe_id }
Se sucesso â†’ publica "payment_completed"
```

**Step 4: EarningsService** (ouve "payment_completed")
```sql
UPDATE payouts SET status = 'completed' WHERE id = 123;
COMMIT;
-- â†’ Fim do saga. Tudo deu certo.
```

**FLUXO COM FALHA (Step 3 falha â€” Stripe retorna erro):**
- Step 1: âœ… payout criado (status='pending')
- Step 2: âœ… wallet creditado (+50.00)
- Step 3: âŒ Stripe falhou!

**COMPENSATIONS (rollback lÃ³gico, na ordem INVERSA):**

Compensate Step 2 â€” WalletService:
```sql
UPDATE wallets SET balance = balance - 50.00 WHERE user_id = 456;
INSERT INTO wallet_transactions (user_id, amount, type, payout_id)
  VALUES (456, -50.00, 'debit_reversal', 123);
COMMIT;
```

Compensate Step 1 â€” EarningsService:
```sql
UPDATE payouts SET status = 'failed', failure_reason = 'payment_declined'
  WHERE id = 123;
COMMIT;
```

> âš ï¸ **IMPORTANTE:** compensations NÃƒO sÃ£o DELETE. SÃ£o novas transaÃ§Ãµes que REVERTEM o efeito lÃ³gico. MantÃ©m audit trail completo.

##### 2 modos de coordenaÃ§Ã£o

| Modo | Como funciona | Pros | Contras | Quando usar |
|------|---------------|------|---------|-------------|
| **Choreography** | Cada serviÃ§o ouve eventos e decide sozinho | Desacoplado, sem SPOF | DifÃ­cil debugar, sem visÃ£o global | Sagas simples (2-3 steps) |
| **Orchestration** â­ | Orchestrator central coordena os steps | ExplÃ­cito, fÃ¡cil debugar/monitorar | SPOF (mitigar com HA) | Sagas complexas, **PAGAMENTOS** |

**Orchestration â€” pseudocÃ³digo:**
```python
def execute_payout(data):
    result1 = earnings_service.create_payout(data)
    if result1.success:
        result2 = wallet_service.credit(data)
        if result2.success:
            result3 = payment_gateway.transfer(data)
            if result3.failure:
                wallet_service.compensate_credit(data)    # rollback step 2
                earnings_service.mark_failed(data)         # rollback step 1
```

##### IdempotÃªncia Ã© OBRIGATÃ“RIA

Cada step pode ser executado mais de 1 vez (retry apÃ³s falha). Sem idempotÃªncia â†’ **pagamento duplicado**.

**Como garantir:**
- Idempotency key: `(payout_id, step_name)` como UNIQUE no banco
- Antes de executar: `SELECT WHERE idempotency_key = X`
  - Se existe â†’ jÃ¡ executou, retorna resultado anterior
  - Se nÃ£o existe â†’ executa e salva resultado

##### Retry Strategy
- **Exponential backoff:** 1s â†’ 2s â†’ 4s â†’ 8s â†’ ...
- **Max retries:** 3-5 tentativas
- **ApÃ³s max retries:** manda para **DLQ** (Dead Letter Queue) para anÃ¡lise manual
- Para pagamentos: **SEMPRE ter DLQ**. Dinheiro nÃ£o pode se perder silenciosamente.

##### Garantias do Saga
- **Eventual consistency:** entre steps, sistema estÃ¡ em estado intermediÃ¡rio
- **Atomicidade "lÃ³gica":** ou tudo completa ou tudo Ã© compensado
- **NÃƒO tem isolamento:** outros processos podem ver estado intermediÃ¡rio (ok para pagamentos â€” status='pending' Ã© visÃ­vel)

##### ReconciliaÃ§Ã£o â­ (a rede de seguranÃ§a final)

Mesmo com saga + idempotÃªncia + DLQ, coisas podem dar errado:
- Compensation falhou silenciosamente
- Rede caiu entre step 2 e step 3, evento perdido
- Bug no cÃ³digo, saldo inconsistente
- Payment gateway cobrou mas nÃ£o retornou resposta (timeout)

**O que Ã©:** processo batch que COMPARA estados entre sistemas e encontra inconsistÃªncias.

**Como funciona mecanicamente:**

**Reconciliation Job** (roda a cada X horas, tipicamente 1x/dia):

**1. EXTRAIR:** puxa registros de cada sistema
```sql
-- Do EarningsService:
SELECT * FROM payouts WHERE date = today;
-- Do WalletService:
SELECT * FROM wallet_transactions WHERE date = today;
-- Do PaymentGateway:
GET /transfers?created[gte]=today
```

**2. COMPARAR** (join lÃ³gico por payout_id):

| earnings_status | wallet_status | gateway_status | Problema? |
|----------------|---------------|----------------|-----------|
| completed | credited | transferred | âœ… OK |
| completed | credited | NOT FOUND | âŒ Pagamento perdido |
| pending | credited | transferred | âŒ Status desatualizado |
| failed | credited | NOT FOUND | âŒ Wallet nÃ£o compensou |
| completed | NOT FOUND | transferred | âŒ Wallet perdeu credit |

**3. GERAR** relatÃ³rio de discrepÃ¢ncias:
- **AutomÃ¡tico:** corrigir casos simples (atualizar status)
- **Manual:** alertar equipe para casos complexos
- **MÃ©tricas:** % de inconsistÃªncias (target: <0.01%)

**4. CORRIGIR:**
- **Auto-fix:** gateway confirma mas status='pending' â†’ `UPDATE payouts SET status='completed'`
- **Manual-fix:** wallet creditou mas gateway nÃ£o transferiu â†’ equipe decide
- **DLQ replay:** reprocessar eventos que falharam

##### Tipos de reconciliaÃ§Ã£o

| Tipo | O que compara | FrequÃªncia |
|------|---------------|------------|
| **Internal** | Seus serviÃ§os entre si (EarningsDB vs WalletDB) | A cada hora |
| **External** | Seu sistema vs terceiro (WalletDB vs Stripe) | DiÃ¡rio (T+1) |
| **Ledger-based** | Double-entry: debit + credit devem somar zero | ContÃ­nuo |

> ğŸ’¡ **Ledger-based:** cada transaÃ§Ã£o tem DEBIT e CREDIT que somam zero.
> Ex: payout $50 â†’ debit empresa + credit reviewer = $0. Se soma â‰  0 â†’ inconsistÃªncia.
> Usado por: Stripe, Wise, Nubank, qualquer fintech sÃ©ria.

**Pitch reconciliaÃ§Ã£o:** *"I'd add a reconciliation job as the final safety net. It runs daily, compares our internal records with the payment gateway, and flags any mismatches."*

**Pitch saga completo:** *"For the payout flow, I'd use an orchestrated saga. Each step is a committed transaction with a compensating action. If the payment gateway fails, we reverse the wallet credit and mark the payout as failed. Idempotency keys prevent duplicate payments. And as a final safety net, a daily reconciliation job catches any edge cases."*

**Camada completa de defesa:**
1. **Saga** â€” happy path + compensations
2. **IdempotÃªncia** â€” previne duplicatas
3. **DLQ** â€” captura falhas apÃ³s retries
4. **ReconciliaÃ§Ã£o** â€” rede de seguranÃ§a final

---

#### 2. Two-Phase Commit (2PC)

**Como funciona mecanicamente:**
```
COORDINATOR envia para todos os PARTICIPANTS:

Phase 1 (PREPARE):
  Coordinator: "Preparem a transaÃ§Ã£o"
  Participant A: executa localmente, NÃƒO commita, responde "READY"
  Participant B: executa localmente, NÃƒO commita, responde "READY"

Phase 2 (COMMIT):
  Se todos READY â†’ Coordinator: "COMMIT todos"
  Se algum ABORT â†’ Coordinator: "ROLLBACK todos"
```

> âš ï¸ **PROBLEMA FATAL:** se coordinator cair entre phase 1 e 2, todos os participants ficam com transaÃ§Ãµes ABERTAS. Deadlock distribuÃ­do. **NÃƒO usar em microservices.**

**Pitch:** *"For distributed transactions, I'd use Saga over 2PC â€” it's non-blocking, more resilient, and scales better for microservices"*

---

## Outbox Pattern â­ (aprendi no mock â€” fixando)

**O que Ã©:** garantir que evento SEMPRE Ã© publicado apÃ³s write no banco.

**Problema:** write no Postgres + publish no Kafka = 2 operaÃ§Ãµes em sistemas diferentes. Se publish falha, evento se perdeu.

### Como funciona mecanicamente

**1. Na MESMA transaÃ§Ã£o:**
```sql
BEGIN;
  INSERT INTO reviews (id, user_id, rating, comment) VALUES (...);
  INSERT INTO outbox (id, event_type, payload, created_at, published)
    VALUES (uuid, 'review_created', '{"review_id":...}', now(), false);
COMMIT;
-- â†’ TransaÃ§Ã£o ACID garante: ambos escritos ou nenhum.
```

**2. Outbox Poller** (processo separado, roda a cada 100-500ms):
```sql
SELECT * FROM outbox WHERE published = false ORDER BY created_at LIMIT 100;
-- Para cada evento: publica no Kafka
-- Se ok: UPDATE outbox SET published = true WHERE id = X;
-- Se falha: tenta no prÃ³ximo ciclo
```

**3. Alternativa ao poller:** CDC (Change Data Capture)
`Postgres WAL â†’ Debezium â†’ Kafka` (automaticamente, sem polling)
Mais elegante, menor latÃªncia, mas mais infra.

**Trade-off:** eventual consistency (delay ms/sec), mas **NUNCA perde evento**.
**Pitch:** *"I'd use the outbox pattern â€” write the record and the event in the same transaction, then a poller publishes to Kafka. Guaranteed delivery."*

---

## Async After 200 â­ (aprendi no mock â€” fixando)

**O que Ã©:** retornar 200 IMEDIATAMENTE apÃ³s source of truth write. Resto Ã© async.

### Como funciona mecanicamente

**ANTES (3 sync operations â€” ERRADO):**
```
Request â†’ [write Postgres] â†’ [INCR Redis] â†’ [publish Queue] â†’ Response 200
LatÃªncia: 5ms + 0.5ms + 2ms = 7.5ms
Se Redis lento (50ms): usuÃ¡rio espera 55.5ms
Se Queue down: request FALHA
```

**DEPOIS (1 sync + rest async â€” CORRETO):**
```
Request â†’ [write Postgres + write outbox] â†’ Response 200
                                             â†“ (async)
                                       [poller â†’ publish Queue]
                                       [worker â†’ INCR Redis]
LatÃªncia para user: 5ms (sÃ³ Postgres)
```

**Por que funciona:**
- Postgres Ã© source of truth. Se estÃ¡ lÃ¡, o dado existe.
- Redis Ã© CACHE â€” pode ser recalculado
- Queue Ã© async por natureza

> ğŸ’¡ **Regra:** *"Write to source of truth, return 200, do everything else async"*

---

## Token Bucket â€” Rate Limiting Algorithm

**O que Ã©:** algoritmo de rate limiting que permite bursts controlados.

### Como funciona mecanicamente â€” passo a passo

**ConfiguraÃ§Ã£o:** `capacity=100, refill_rate=10/min`

**Estado armazenado (por user, no Redis):**
```
Key: rate_limit:{user_id}
Value: { tokens: 100, last_refill: 1740000000 }
```

**Quando chega um request:**
1. Ler estado atual: `tokens=85, last_refill=1740000060`
2. Calcular tokens acumulados desde last_refill:
   ```
   elapsed = now - last_refill = 30 seconds
   new_tokens = elapsed Ã— (refill_rate / 60) = 30 Ã— (10/60) = 5 tokens
   ```
3. Atualizar: `min(tokens + new_tokens, capacity) = min(85+5, 100) = 90`
4. Tem token?
   - **SIM** (90 > 0): `tokens = 90 - 1 = 89`. Permitir. Atualizar Redis.
   - **NÃƒO** (0): Rejeitar com `429 Too Many Requests`.
5. Salvar: `{ tokens: 89, last_refill: now }`

> â­ **O REFILL NÃƒO Ã‰ UM PROCESSO SEPARADO** â€” Ã© calculado em tempo de execuÃ§Ã£o!
> Cada request calcula quantos tokens acumularam desde a Ãºltima vez.
> Isso Ã© chamado de **"lazy refill"** â€” nenhum background job necessÃ¡rio.

### ImplementaÃ§Ã£o atÃ´mica com Redis (Lua script)
```lua
local key = KEYS[1]
local capacity = tonumber(ARGV[1])       -- 100
local refill_rate = tonumber(ARGV[2])    -- 10 per minute
local now = tonumber(ARGV[3])
local tokens = redis.call('HGET', key, 'tokens') or capacity
local last = redis.call('HGET', key, 'last_refill') or now
local elapsed = now - last
tokens = math.min(tokens + elapsed * refill_rate / 60, capacity)
if tokens >= 1 then
  tokens = tokens - 1
  redis.call('HSET', key, 'tokens', tokens, 'last_refill', now)
  return 1  -- allowed
else
  return 0  -- rejected
end
```

### Por que Ã© melhor que Fixed/Sliding Window
- **Fixed Window:** user faz 99 req no segundo 59 + 100 no segundo 61 = 199 em 2 seg. Boundary burst!
- **Token Bucket:** capacity Ã© o MÃXIMO de burst. Depois, limitado pela refill rate.
- Permite **bursts controlados**: user idle por 10 min acumula tokens
- Configs diferentes por endpoint: `/api/search` (100/min), `/api/payment` (10/min)

---

## CAP Theorem

Em sistema distribuÃ­do, escolha 2 de 3:
- **C**onsistency: todos os nÃ³s veem o mesmo dado
- **A**vailability: toda request recebe resposta
- **P**artition tolerance: funciona com falha de rede

PartiÃ§Ãµes SEMPRE podem acontecer â†’ escolha real Ã© **CP vs AP**:

| Escolha | Comportamento | Exemplo |
|---------|---------------|---------|
| **CP** | Pode ficar indisponÃ­vel durante partiÃ§Ã£o | Pagamentos, saldo, inventory |
| **AP** | Responde mas dado pode estar stale | Reviews, feeds, likes, cache |

> ğŸ’¡ *"For reviews, AP â€” eventual consistency is fine. For payouts, CP â€” consistency is critical to avoid duplicate payments"*

---

# 3. Problemas de System Design Praticados

## Rate Limiter
- **Onde vive:** API Gateway (borda). NÃƒO dentro de cada serviÃ§o.
- **Algoritmos:** Fixed Window, Sliding Window Log/Counter, Token Bucket
- **Storage:** Redis (sub-ms, atÃ´mico, distribuÃ­do)
- **Fail mode:** fail-open (permite tudo) vs fail-closed (bloqueia tudo)
- **Trade-off:** Availability > Consistency

## Uber / Ride Matching
- **Fluxo:** Rider â†’ Fare Service â†’ Matching Service â†’ Driver notification
- **Entidades:** rider, driver, trip, fare, location
- **Gaps que preciso fixar:**
  - Geospatial: Geohash/QuadTree/S2 Cells
  - Real-time: WebSocket para location streaming
  - ETA: graph algorithms + trÃ¢nsito
  - Surge pricing: demand/supply ratio

## Food Reviews + Payouts (mock 24/fev â€” Borderline Hire)
- **Fortes:** entities, APIs, Redis INCR, queue separation, DLQ, idempotency
- **Gaps:** (1) napkin math, (2) async critical path, (3) wrap-up trade-offs
- **Wrap-up modelo (MEMORIZAR):**
  *"The key trade-off is eventual consistency on vote counts â€” users might see slightly stale counts, but we get sub-100ms response times. For payouts, strong consistency with unique constraint prevents duplicates, accepting higher latency. With more time: notification service, fraud detection."*

## Job Scheduler
- **Entidades:** task, job, execution, schedule, user
- **Componentes:** JobService â†’ SchedulerService â†’ Queue â†’ WorkerService
- **Scaling:** partitioned scheduling `hash(job_id) % N`, auto-scale workers, DLQ

---

# 4. Napkin Math â€” ReferÃªncia RÃ¡pida

### LatÃªncias
| OperaÃ§Ã£o | LatÃªncia |
|----------|----------|
| L1 cache | 0.5 ns |
| RAM | 100 ns |
| SSD read | 150 Î¼s |
| Network round trip (datacenter) | 500 Î¼s |
| Redis | <1 ms |
| Postgres simple | 1-5 ms |
| Postgres complex | 10-100 ms |

### Throughput (single node)
| Sistema | Throughput |
|---------|-----------|
| Redis | 100K-300K ops/sec |
| Postgres inserts | 5,000-10,000/sec |
| Postgres indexed reads | 10,000-50,000/sec |
| Kafka | 1M+ msgs/sec (cluster) |

### Storage
| Escala | Tamanho |
|--------|---------|
| 1M rows Ã— 1KB | 1 GB |
| 1B rows Ã— 1KB | 1 TB |

### QPS Calculation
```
DAU / 86,400 = average QPS
Peak = 3-5x average
Ex: 30M orders/day = ~350 QPS avg, ~1,750 peak
```

---

# 5. Framework SD (usar em TODA entrevista)

| Fase | Tempo | O que fazer |
|------|-------|-------------|
| 1. Requirements | 5 min | Functional + Non-functional. **PERGUNTAR ESCALA!** |
| 2. Core Entities | 3 min | Entidades + relacionamentos |
| 3. API Design | 5 min | Endpoints principais (REST) |
| 4. High-Level | 5 min | Diagrama com componentes |
| 5. Deep Dive | 25 min | 2-3 componentes. **AQUI mostra senioridade.** |
| 6. Scaling | 10 min | Bottlenecks + nÃºmeros + trade-offs |
| 7. Wrap-up | 5 min | Resumir decisÃµes + o que faria com mais tempo |

### Regras
- âœ… SEMPRE perguntar nÃºmeros (QPS, users, storage)
- âœ… SEMPRE napkin math ANTES de propor scaling
- âœ… SEMPRE articular trade-offs: *"We chose X over Y because Z, accepting W"*
- âœ… SEMPRE estruturar: *"There are N things: first... second... third..."*
- âœ… Source of truth write â†’ return 200 â†’ rest is async
- âŒ NÃ£o propor sharding se single node aguenta os nÃºmeros

---

# 6. Decision Cards

| Tool/Pattern | Quando usar | Quando NÃƒO usar |
|--------------|-------------|-----------------|
| **Redis** | Cache, counters, rate limit, locks | Durabilidade, joins, >RAM |
| **Kafka** | Event streaming, desacoplamento | Req-response, baixo volume |
| **PostgreSQL** | Source of truth, ACID, relationships | >10K writes/sec, no relations |
| **Outbox** | Write + event na mesma transaÃ§Ã£o | Quando eventual consist. â‰  ok |
| **Async after 200** | Side effects nÃ£o essenciais | User PRECISA do resultado |
| **Saga** | TransaÃ§Ãµes distribuÃ­das | Tudo cabe em 1 banco |
| **2PC** | Quase nunca em microservices | Sempre que puder usar Saga |
| **Pessimistic Lock** | Conflitos frequentes | Baixa contenÃ§Ã£o |
| **OCC** | Conflitos raros | Alta contenÃ§Ã£o |
| **Token Bucket** | Rate limit com bursts | Fixed window basta |
| **Sorted Set** | Leaderboards, top-N | Dados com joins |
| **DLQ** | Pagamentos, processos crÃ­ticos | Eventos descartÃ¡veis |
| **WebSocket** | Real-time bidirecional | Unidirecional (usar SSE) |
| **SSE** | Real-time serverâ†’client only | Client precisa enviar dados |
| **Read Replicas** | Read-heavy, tolera stale | Precisa strong consistency |
| **Cache-Aside** | Read-heavy, miss tolerÃ¡vel | Write-heavy |
| **Fan-out on Write** | Poucos followers | Celebridades (write amplif.) |
| **Fan-out on Read** | Celebridades | Users normais (leitura lenta) |
| **ReconciliaÃ§Ã£o** | Pagamentos, dados financeiros | InconsistÃªncia Ã© aceitÃ¡vel |
 1. The live donation counter

  You're using INCR after Stripe success. But the requirement was near real-time counter visible to all users on
  the page. How do millions of users SEE the counter update? They're all on the donations page â€” do they poll?
  WebSocket? SSE? Which one and why?

R: isso nao estava no requerimentos, mas se voce esta falando para fazermos agora, podemos ter duas abordagens:
1 - manter a agregacao por charity, e ter um worker separado que agrega a cada X segundos todos os valores totais da caridade e manda para o front end via sse
2 - quando o transaction worker incrementa o valor da charity, tambem podemos ter uma outra chave(campaign_id) que incrementamos o valor total

  2. Step 2 â€” you said atomic transaction with INSERT donation + INSERT transaction

  Why are you creating the transaction record BEFORE calling Stripe? The transaction should be created by the
  worker AFTER it picks up the job. Otherwise if the worker never picks it up, you have an orphaned transaction
  record in INITIATED state forever. What's your reasoning?

R estamos criando uma transacao para manter todo o historico, pois caso ocorra uma falha com o stripe, eu posso marcar que aquela transacao
nao foi efetuada e colocar ela na fila de DQL para fazer a reconsiliacao depois, isso serve tambem para termos toda a auditoria das doacoes em caso de governanca interna
E se o worker nao pegou, quer dizer que eu tive uma falha antes de enviar para o stripe, e por isso eu posso reprocessar a transacao

3 Campaign ends in 24-48 hours
  What happens to in-flight donations when the campaign closes? User clicks donate at hour 47:59, payment
  processes at hour 48:01. Is it accepted or rejected? How do you handle this edge case?

Bom ponto, realmente nao coloque isso. E talvez a melhor abordagem para isso Ã© colocar uma chave no redis com um TTL
de 48. Todas as requisicoes que entram na aplicacao passam por essa chave, e se ela for valida, a requisicao segue,
se ela ja foi expirada, a requisicao retorna uma mensagem dizendo que a campanha acabou. Assim a gente protege a aplicacao de
receber requisicoes e ter que validar essa regra toda vez

Now, scaling question. It's hour 1 of the campaign. A celebrity tweets "Donate on DoorDash!" and
  your traffic spikes 50x â€” from 8 QPS to 400 QPS in minutes. Millions hitting the page.

Following the data flow:
Redis to check campaign data can handle with 400qps
Load balancer will route the requests to DonationService that is deployad in AKS pods and can slace based on requests/cpu/memory
Postgres write: can handle with 5-10k writes per seconds, so this is ok also
Postgres read: can handle with 50-100k reads per seconds, but will be important to create a index in some specific tables like charity and donations. I dont think its necesasry to create read replicas
One thing that we can scale its the TransactionWorker to suport 50x more transactions, so we can also scale horizontaly
And finally for redis just in case we can have a HA, but redis will be also fine because will suport 100-300k ops sec

functional req
customer should be able to see where the drivers is in real time on map
driver should be able to send location informations to the user

nonfunctional req
availability > consistent its ok to lose one lat long from the driver and have eventual consistency
driver should send the locations every 2-3 seconds with low latency
customer should see the locations with low latency

numbers

10m / 10000k = 100QPS
30m active order * 60 = 1800sec
100 * 1800 = 18000 sessions
write qps = 18000 * 0.5 = 90000
peak = 90000 * 3 = 270000

with this numbers i can see that relational database will not handle with that
we need a stream(kafka, etc)
we need  in memory database due latency reqs
we need sharding
we need a real time update for the customers(websocket or sse)

core entities
order = id, amount, customer_id...
customer = id, name, document, phone..
driver = id, name, document, phone..
location event = id, lat, long, order_id, customer_id, driver_id...

apis
post -> /drivers/location
requests = {
  driver_id = xx,
  order_id = xx,
  lat = xx,
  long = xx,
  timestamp = xx
}

response = {
  "ok"
}

get -> /order/:orderId
response = {
  order_id = xx,
  status = xx,
  driver_id = xx,
}

get -> /order/:orderId/location
response = {
  lat = xx,
  long = xx,
  driver_id = xx,
}

wss:/order/:orderId/location/realtime
response = {
  lat = xx,
  long = xx,
  driver_id = xx,
}


hdl
Componentes
ğŸ”¹ Edge Layer

Load Balancer

API Gateway

ğŸ”¹ Application Layer

Location API

Order API

WebSocket Realtime Gateway

Location Processor

ğŸ”¹ Data & Messaging

Kafka (driver-location topic)

Redis (latest driver state)

PostgreSQL (orders, drivers, customers)

2ï¸âƒ£ Arquitetura Geral
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚      Driver App        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ LoadBalancer â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ API Gateway  â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ Location API â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Kafka Topic          â”‚
                          â”‚ driver-location      â”‚
                          â”‚ (N partitions)       â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Location Processor  â”‚           â”‚ WebSocket Gateway    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                 â”‚
                    â–¼                                 â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   Redis      â”‚                  â”‚ Customer App â”‚
             â”‚ latest state â”‚                  â”‚  (WebSocket) â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
3ï¸âƒ£ Data Flow â€” Driver
Driver App
   â†“
Load Balancer
   â†“
API Gateway
   â†“
Location API
   â†“
Kafka (partition by driver_id)

4ï¸âƒ£ Data Flow â€” Internal Processing
Kafka
   â†“
Location Processor
   â†“
Redis
(driver:{id}:location = latest lat/lng)

5ï¸âƒ£ Data Flow â€” Customer (Initial Request)
Customer App
   â†“
Load Balancer
   â†“
API Gateway
   â†“
Order API
   â†“
PostgreSQL (get driver_id)
   â†“
Redis (get latest location)
   â†“
Return initial lat/lng

6ï¸âƒ£ Data Flow â€” Customer (Realtime)
Customer App
   â†“
Load Balancer (WebSocket support)
   â†“
WebSocket Gateway
   â†“
(Register order_id â†’ connection)

new location:
Kafka
   â†“
WebSocket Gateway (consumer group)
   â†“
Filter interested connections
   â†“
Push via WebSocket
   â†“. 
Customer App updates map

deep dives
how we can scale and availability the websockets?
we can have a loadbalancer with distributed connections to route the request to websockets
we can also have websockets deployed on kubernetes and have HPA

redis will support this massive writes every time for update the driver location?
we can go to a redis cluster strategy sharded


how redis will manage and ttl and read scale?
we can have a 30 sec ttl. if the driver dont send anything we remove the key and clean the memory
also with redis cluster we can have a read replicas to support shard by driver_id

how we will scale kafka? supposed we have more order in the future, just one topic will handle?
one topic will be ok. we need just to check the partition strategy, brokers e consumer groups
we can incrase the numer of partition to suport horizontal scalability or add more brokers
also if we have more than 1 location, we can create topics based on regions

1) 20M users, 5% DAU, each user sends 10 messages/day. Message = 500 bytes. Write QPS? Storage/month?           
messages day = 1m dau * 10 = 10m
write qps = 10m / 100k = 100
storage month = 10m * 5gb dia; ~150gbmes

2) 3M orders/day, each order triggers 2 Kafka events, each event = 1KB. Events/sec?
Storage/week?
3m * 2 = 6m events
6m / 100k = 60qps

3) 200K concurrent drivers, each sends GPS ping every 3 seconds. Pings/sec? Each ping = 100
bytes, bandwidth?

200k / 3 = 66pings/sec
66 * 100 = 6k/sec bandwidth

1 KB  â‰ˆ 10Â³ bytes  (1.000)
1 MB  â‰ˆ 10â¶ bytes
1 GB  â‰ˆ 10â¹ bytes
1 TB  â‰ˆ 10Â¹Â² bytes